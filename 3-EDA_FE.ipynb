{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os \n",
    "import json\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Lo ejecuto por unica vez\n",
    "# import nltk\n",
    "# nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './'\n",
    "\n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"data/train/train.csv\")\n",
    "#Salida de modelos entrenados\n",
    "PATH_TO_MODELS = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/models\")\n",
    "\n",
    "#Artefactos a subir a optuna\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_temp_artifacts\")\n",
    "\n",
    "#Artefactos que optuna gestiona\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_artifacts\")\n",
    "PATH_TO_IMAGES = os.path.join(BASE_DIR, \"data/train_images\")\n",
    "PATH_TO_SENTIMENTS = os.path.join(BASE_DIR, \"data/train_sentiment\")\n",
    "PATH_TO_SENTIMENTS_SAVE = os.path.join(BASE_DIR, \"data/train\")\n",
    "\n",
    "\n",
    "SEED = 55 #Semilla de procesos aleatorios (para poder replicar exactamente al volver a correr un modelo)\n",
    "BATCH_SIZE= 50\n",
    "TEST_SIZE = 0.2 #Facción para train/test= split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train/train.csv')\n",
    "color_labels=pd.read_csv('./data/color_labels.csv')\n",
    "state_labels=pd.read_csv('./data/state_labels.csv')\n",
    "breed_labels=pd.read_csv('./data/breed_labels.csv')\n",
    "\n",
    "train = train.merge(breed_labels, left_on=['Breed1', 'Type'], right_on=['BreedID', 'Type'], how='left', suffixes=('', '_PrimaryBreed'))\n",
    "train = train.merge(breed_labels, left_on=['Breed2', 'Type'], right_on=['BreedID', 'Type'], how='left', suffixes=('', '_SecondaryBreed'))\n",
    "\n",
    "\n",
    "train_image_files = sorted(glob.glob('./data/train_images/*.jpg'))\n",
    "train_sentiments_files = sorted(glob.glob('./data/train_sentiment/*.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrego el campo objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear los límites para las categorías\n",
    "bins = [-1, 3, 6, 12, 24, 36, 72, 144, np.inf]  # Empieza en -1 para incluir el 0\n",
    "\n",
    "# Crear los nombres de las categorías\n",
    "labels = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "# Crear la nueva columna 'age_target' utilizando pd.cut\n",
    "train['Age_target'] = pd.cut(train['Age'], bins=bins, labels=labels, right=True, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>BreedID</th>\n",
       "      <th>BreedName</th>\n",
       "      <th>BreedID_SecondaryBreed</th>\n",
       "      <th>BreedName_SecondaryBreed</th>\n",
       "      <th>Age_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>86e1089a3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>299.0</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>6296e909a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>3422e4906</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>307.0</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "\n",
       "   MaturitySize  ...  VideoAmt  \\\n",
       "0             1  ...         0   \n",
       "1             2  ...         0   \n",
       "2             2  ...         0   \n",
       "\n",
       "                                         Description      PetID  PhotoAmt  \\\n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3       1.0   \n",
       "1  I just found it alone yesterday near my apartm...  6296e909a       2.0   \n",
       "2  Their pregnant mother was dumped by her irresp...  3422e4906       7.0   \n",
       "\n",
       "   AdoptionSpeed  BreedID             BreedName  BreedID_SecondaryBreed  \\\n",
       "0              2    299.0                 Tabby                     NaN   \n",
       "1              0    265.0  Domestic Medium Hair                     NaN   \n",
       "2              3    307.0           Mixed Breed                     NaN   \n",
       "\n",
       "  BreedName_SecondaryBreed  Age_target  \n",
       "0                      NaN           0  \n",
       "1                      NaN           0  \n",
       "2                      NaN           0  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Analisìs de Images and Sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Imagenes para procesar: 58311\n",
      "Numero de Archivos JSON para procesar: 14442\n",
      "Porcentaje de mascotas con imagenes: 0.977\n",
      "Porcentaje de mascotas con archivos de sentimientos: 0.963\n"
     ]
    }
   ],
   "source": [
    "print('Numero de Imagenes para procesar: {}'.format(len(train_image_files)))\n",
    "print('Numero de Archivos JSON para procesar: {}'.format(len(train_sentiments_files)))\n",
    "\n",
    "\n",
    "# Images\n",
    "trainIds= train[['PetID']]\n",
    "train_df_images = pd.DataFrame(train_image_files)\n",
    "train_df_images.columns = ['image_filename']\n",
    "train_images_pet = train_df_images['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\n",
    "train_df_images = train_df_images.assign(PetId=train_images_pet)\n",
    "\n",
    "pet_with_images = len(np.intersect1d(train_images_pet.unique(), trainIds['PetID'].unique() ))\n",
    "print('Porcentaje de mascotas con imagenes: {:.3f}'.format(pet_with_images/ trainIds.shape[0]))\n",
    "\n",
    "# Sentiments\n",
    "trainIds= train[['PetID']]\n",
    "train_df_sentiments = pd.DataFrame(train_sentiments_files)\n",
    "train_df_sentiments.columns = ['sentiment_filename']\n",
    "train_sentiment_pet = train_df_sentiments['sentiment_filename'].apply(lambda x: x.split('/')[-1].split('.')[0])\n",
    "train_df_sentiments = train_df_sentiments.assign(PetId=train_sentiment_pet)\n",
    "\n",
    "pet_with_sentiment = len(np.intersect1d(train_sentiment_pet.unique(), trainIds['PetID'].unique() ))\n",
    "print('Porcentaje de mascotas con archivos de sentimientos: {:.3f}'.format(pet_with_sentiment/ trainIds.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para tratar los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_sentiment_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename) as f:\n",
    "            sentiment_data = json.load(f)\n",
    "            return sentiment_data\n",
    "    else:\n",
    "        return None\n",
    "       \n",
    "        \n",
    "def open_images_file(filename):\n",
    "    image = np.asarray(Image.open( filename))\n",
    "    return image\n",
    "\n",
    "def interprete_sentence(scoreValue):\n",
    "    if scoreValue is None:\n",
    "        return \"unknown\"\n",
    "    elif scoreValue> 0.25:\n",
    "        return \"postive\"\n",
    "    elif scoreValue< 0.25:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura de los archivos JSON con los resultados del sentimental analysis de Natural Lenguaje features API \n",
    "\n",
    "documentSentiment\n",
    "1. score of the sentiment ranges between -1.0 (negative) and 1.0 (positive) and corresponds to the overall emotional leaning of the text.\n",
    "2. magnitude indicates the overall strength of emotion (both positive and negative) within the given text, between 0.0 and +inf. Unlike score, magnitude is not normalized for documentSentiment; each expression of emotion within the text (both positive and negative) contributes to the text's magnitude (so longer text blocks may have greater magnitudes)\n",
    "\n",
    "sentences\n",
    "\n",
    "1. Sentiment contains the sentence level sentiment values attached to each sentence, which contain score between -1.0 (negative) and 1.0 (positive) as and magnitude values between 0.0 and 1.0. Note that magnitude for sentences is normalized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar los resultados\n",
    "data = []\n",
    "\n",
    "# Recorremos todos los archivos en el directorio\n",
    "for archivo in train_sentiment_pet.unique():\n",
    "    sentiment_data = open_sentiment_file(os.path.join(PATH_TO_SENTIMENTS, archivo +'.json'))  \n",
    "    # Extraer el score y magnitude de 'documentSentiment'\n",
    "    doc_sentiment_score = sentiment_data['documentSentiment']['score']\n",
    "    doc_sentiment_magnitude = sentiment_data['documentSentiment']['magnitude']\n",
    "    entity_name = ' '.join(entity['name'] for entity in sentiment_data.get('entities', []))\n",
    "        \n",
    "    # Recorrer cada oración dentro del campo 'sentences'\n",
    "    for sentence in sentiment_data.get('sentences', []):\n",
    "        sentence_text = sentence['text']['content']\n",
    "        sentence_sentiment_score = sentence['sentiment']['score']\n",
    "        sentence_sentiment_magnitude = sentence['sentiment']['magnitude']\n",
    "        # Guardar los datos en la lista\n",
    "\n",
    "        data.append({\n",
    "            'PetID': archivo,\n",
    "            'doc_sentiment_score': doc_sentiment_score,\n",
    "            'doc_score': interprete_sentence(doc_sentiment_score),\n",
    "            'doc_sentiment_magnitude': doc_sentiment_magnitude,\n",
    "            'doc_magnitude': interprete_sentence(doc_sentiment_magnitude),\n",
    "            'entity_name': entity_name,\n",
    "            'sentence_sentiment_score': sentence_sentiment_score,\n",
    "            'sentence_score': interprete_sentence(sentence_sentiment_score),\n",
    "            'sentence_sentiment_magnitude': sentence_sentiment_magnitude,\n",
    "            'sentence_magnitude': interprete_sentence(sentence_sentiment_magnitude)\n",
    "            })\n",
    "\n",
    "# Convertir los datos a un DataFrame de pandas\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(PATH_TO_SENTIMENTS_SAVE, 'train_sentimentFE.csv'),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>doc_sentiment_score</th>\n",
       "      <th>doc_score</th>\n",
       "      <th>doc_sentiment_magnitude</th>\n",
       "      <th>doc_magnitude</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>sentence_sentiment_score</th>\n",
       "      <th>sentence_score</th>\n",
       "      <th>sentence_sentiment_magnitude</th>\n",
       "      <th>sentence_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.7</td>\n",
       "      <td>postive</td>\n",
       "      <td>2.8</td>\n",
       "      <td>postive</td>\n",
       "      <td>Ollie construction site house manja type playm...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.7</td>\n",
       "      <td>postive</td>\n",
       "      <td>2.8</td>\n",
       "      <td>postive</td>\n",
       "      <td>Ollie construction site house manja type playm...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>postive</td>\n",
       "      <td>0.9</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.7</td>\n",
       "      <td>postive</td>\n",
       "      <td>2.8</td>\n",
       "      <td>postive</td>\n",
       "      <td>Ollie construction site house manja type playm...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>postive</td>\n",
       "      <td>0.9</td>\n",
       "      <td>postive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  doc_sentiment_score doc_score  doc_sentiment_magnitude  \\\n",
       "0  0008c5398                  0.7   postive                      2.8   \n",
       "1  0008c5398                  0.7   postive                      2.8   \n",
       "2  0008c5398                  0.7   postive                      2.8   \n",
       "\n",
       "  doc_magnitude                                        entity_name  \\\n",
       "0       postive  Ollie construction site house manja type playm...   \n",
       "1       postive  Ollie construction site house manja type playm...   \n",
       "2       postive  Ollie construction site house manja type playm...   \n",
       "\n",
       "   sentence_sentiment_score sentence_score  sentence_sentiment_magnitude  \\\n",
       "0                       0.0       negative                           0.0   \n",
       "1                       0.9        postive                           0.9   \n",
       "2                       0.9        postive                           0.9   \n",
       "\n",
       "  sentence_magnitude  \n",
       "0           negative  \n",
       "1            postive  \n",
       "2            postive  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupo caracteristicas extraidas por PETID.\n",
    "\n",
    "Del archivo JSON voy almacenar:\n",
    "1. documentSentiment: score, magnitude.\n",
    "2. sentences: scrore, magnitude.\n",
    "3. entities: name.\n",
    "4. Creo una columna mean y sum para cada caracteristica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfFE = pd.read_csv(os.path.join(PATH_TO_SENTIMENTS_SAVE, 'train_sentimentFE.csv'))\n",
    "train_dfFE = train_dfFE.drop(['doc_score','doc_magnitude','sentence_score','sentence_magnitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>doc_sentiment_score</th>\n",
       "      <th>doc_sentiment_magnitude</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>sentence_sentiment_score</th>\n",
       "      <th>sentence_sentiment_magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Ollie construction site house manja type playm...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Ollie construction site house manja type playm...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Ollie construction site house manja type playm...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Ollie construction site house manja type playm...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000a290e4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>restaurant puppies beach Call teluk kumba Adop...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73880</th>\n",
       "      <td>fff6f2f61</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>puppies adoption terrier pups mongrel skin pro...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73881</th>\n",
       "      <td>fff6f2f61</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>puppies adoption terrier pups mongrel skin pro...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73882</th>\n",
       "      <td>fffd78a11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>people litter box kids kitten</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73883</th>\n",
       "      <td>fffd78a11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>people litter box kids kitten</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73884</th>\n",
       "      <td>fffd9b5a8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>type dog. walk energy</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73885 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PetID  doc_sentiment_score  doc_sentiment_magnitude  \\\n",
       "0      0008c5398                  0.7                      2.8   \n",
       "1      0008c5398                  0.7                      2.8   \n",
       "2      0008c5398                  0.7                      2.8   \n",
       "3      0008c5398                  0.7                      2.8   \n",
       "4      000a290e4                  0.3                      0.6   \n",
       "...          ...                  ...                      ...   \n",
       "73880  fff6f2f61                  0.5                      3.3   \n",
       "73881  fff6f2f61                  0.5                      3.3   \n",
       "73882  fffd78a11                  0.8                      1.6   \n",
       "73883  fffd78a11                  0.8                      1.6   \n",
       "73884  fffd9b5a8                  0.9                      0.9   \n",
       "\n",
       "                                             entity_name  \\\n",
       "0      Ollie construction site house manja type playm...   \n",
       "1      Ollie construction site house manja type playm...   \n",
       "2      Ollie construction site house manja type playm...   \n",
       "3      Ollie construction site house manja type playm...   \n",
       "4      restaurant puppies beach Call teluk kumba Adop...   \n",
       "...                                                  ...   \n",
       "73880  puppies adoption terrier pups mongrel skin pro...   \n",
       "73881  puppies adoption terrier pups mongrel skin pro...   \n",
       "73882                      people litter box kids kitten   \n",
       "73883                      people litter box kids kitten   \n",
       "73884                              type dog. walk energy   \n",
       "\n",
       "       sentence_sentiment_score  sentence_sentiment_magnitude  \n",
       "0                           0.0                           0.0  \n",
       "1                           0.9                           0.9  \n",
       "2                           0.9                           0.9  \n",
       "3                           0.8                           0.8  \n",
       "4                           0.1                           0.1  \n",
       "...                         ...                           ...  \n",
       "73880                       0.9                           0.9  \n",
       "73881                       0.1                           0.1  \n",
       "73882                       0.9                           0.9  \n",
       "73883                       0.7                           0.7  \n",
       "73884                       0.9                           0.9  \n",
       "\n",
       "[73885 rows x 6 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dfFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentiment_desc = train_dfFE[['PetID', 'entity_name']].drop_duplicates()\n",
    "train_dfFE = train_dfFE.drop(['entity_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>doc_sentiment_score_MEAN</th>\n",
       "      <th>doc_sentiment_score_SUM</th>\n",
       "      <th>doc_sentiment_magnitude_MEAN</th>\n",
       "      <th>doc_sentiment_magnitude_SUM</th>\n",
       "      <th>sentence_sentiment_score_MEAN</th>\n",
       "      <th>sentence_sentiment_score_SUM</th>\n",
       "      <th>sentence_sentiment_magnitude_MEAN</th>\n",
       "      <th>sentence_sentiment_magnitude_SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008c5398</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a290e4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000fb9572</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011d7c25</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00156db4a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  doc_sentiment_score_MEAN  doc_sentiment_score_SUM  \\\n",
       "0  0008c5398                       0.7                      2.8   \n",
       "1  000a290e4                       0.3                      0.6   \n",
       "2  000fb9572                       0.3                      0.6   \n",
       "3  0011d7c25                       0.8                      0.8   \n",
       "4  00156db4a                       0.0                      0.0   \n",
       "\n",
       "   doc_sentiment_magnitude_MEAN  doc_sentiment_magnitude_SUM  \\\n",
       "0                           2.8                         11.2   \n",
       "1                           0.6                          1.2   \n",
       "2                           0.8                          1.6   \n",
       "3                           0.8                          0.8   \n",
       "4                           1.8                          9.0   \n",
       "\n",
       "   sentence_sentiment_score_MEAN  sentence_sentiment_score_SUM  \\\n",
       "0                           0.65                           2.6   \n",
       "1                           0.30                           0.6   \n",
       "2                           0.35                           0.7   \n",
       "3                           0.80                           0.8   \n",
       "4                           0.02                           0.1   \n",
       "\n",
       "   sentence_sentiment_magnitude_MEAN  sentence_sentiment_magnitude_SUM  \n",
       "0                               0.65                               2.6  \n",
       "1                               0.30                               0.6  \n",
       "2                               0.35                               0.7  \n",
       "3                               0.80                               0.8  \n",
       "4                               0.34                               1.7  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_list = ['mean', 'sum']\n",
    "\n",
    "for i in train_dfFE.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_dfFE[i] = train_dfFE[i].astype(float)\n",
    "train_dfFE = train_dfFE.groupby(['PetID']).agg(function_list)\n",
    "\n",
    "\n",
    "train_dfFE.columns = pd.Index(['{}_{}'.format(\n",
    "            c[0], c[1].upper()) for c in train_dfFE.columns.tolist()])\n",
    "train_dfFE = train_dfFE.reset_index()\n",
    "\n",
    "train_dfFE.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge de los dos dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfFE = train_dfFE.merge(train_sentiment_desc, how='left', on='PetID')\n",
    "train= train.merge(train_dfFE,how='left',on='PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_target</th>\n",
       "      <th>doc_sentiment_score_MEAN</th>\n",
       "      <th>doc_sentiment_score_SUM</th>\n",
       "      <th>doc_sentiment_magnitude_MEAN</th>\n",
       "      <th>doc_sentiment_magnitude_SUM</th>\n",
       "      <th>sentence_sentiment_score_MEAN</th>\n",
       "      <th>sentence_sentiment_score_SUM</th>\n",
       "      <th>sentence_sentiment_magnitude_MEAN</th>\n",
       "      <th>sentence_sentiment_magnitude_SUM</th>\n",
       "      <th>entity_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Nibble cuteness clinic cats result kitty coupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>apartment care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>3.4</td>\n",
       "      <td>mother owner puppies roadside shops Subang Jay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>guard dog master obedience call sms details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>boy adoption Hunter pal puppies love age brat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "4     1       Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize  ...  Age_target  doc_sentiment_score_MEAN  \\\n",
       "0             1  ...           0                       0.3   \n",
       "1             2  ...           0                      -0.2   \n",
       "2             2  ...           0                       0.2   \n",
       "3             2  ...           1                       0.9   \n",
       "4             2  ...           0                       0.6   \n",
       "\n",
       "   doc_sentiment_score_SUM  doc_sentiment_magnitude_MEAN  \\\n",
       "0                      1.8                           2.4   \n",
       "1                     -0.4                           0.7   \n",
       "2                      1.4                           3.7   \n",
       "3                      0.9                           0.9   \n",
       "4                      3.6                           3.7   \n",
       "\n",
       "   doc_sentiment_magnitude_SUM  sentence_sentiment_score_MEAN  \\\n",
       "0                         14.4                       0.300000   \n",
       "1                          1.4                      -0.250000   \n",
       "2                         25.9                       0.200000   \n",
       "3                          0.9                       0.900000   \n",
       "4                         22.2                       0.583333   \n",
       "\n",
       "   sentence_sentiment_score_SUM  sentence_sentiment_magnitude_MEAN  \\\n",
       "0                           1.8                           0.366667   \n",
       "1                          -0.5                           0.350000   \n",
       "2                           1.4                           0.485714   \n",
       "3                           0.9                           0.900000   \n",
       "4                           3.5                           0.583333   \n",
       "\n",
       "  sentence_sentiment_magnitude_SUM  \\\n",
       "0                              2.2   \n",
       "1                              0.7   \n",
       "2                              3.4   \n",
       "3                              0.9   \n",
       "4                              3.5   \n",
       "\n",
       "                                         entity_name  \n",
       "0  Nibble cuteness clinic cats result kitty coupl...  \n",
       "1                                     apartment care  \n",
       "2  mother owner puppies roadside shops Subang Jay...  \n",
       "3        guard dog master obedience call sms details  \n",
       "4  boy adoption Hunter pal puppies love age brat ...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completo los campos NA y vuelvo a guardar el archivo con el analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completo con MISSING los campos nulos de entity name\n",
    "train['entity_name'] = train['entity_name'].fillna('<MISSING>')\n",
    "train['Description'] = train['Description'].fillna('<MISSING>')\n",
    "train.to_csv(os.path.join(PATH_TO_SENTIMENTS_SAVE, 'train_sentimentFE.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_target</th>\n",
       "      <th>doc_sentiment_score_MEAN</th>\n",
       "      <th>doc_sentiment_score_SUM</th>\n",
       "      <th>doc_sentiment_magnitude_MEAN</th>\n",
       "      <th>doc_sentiment_magnitude_SUM</th>\n",
       "      <th>sentence_sentiment_score_MEAN</th>\n",
       "      <th>sentence_sentiment_score_SUM</th>\n",
       "      <th>sentence_sentiment_magnitude_MEAN</th>\n",
       "      <th>sentence_sentiment_magnitude_SUM</th>\n",
       "      <th>entity_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Nibble cuteness clinic cats result kitty coupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>apartment care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>3.4</td>\n",
       "      <td>mother owner puppies roadside shops Subang Jay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>guard dog master obedience call sms details</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "\n",
       "   MaturitySize  ...  Age_target  doc_sentiment_score_MEAN  \\\n",
       "0             1  ...           0                       0.3   \n",
       "1             2  ...           0                      -0.2   \n",
       "2             2  ...           0                       0.2   \n",
       "3             2  ...           1                       0.9   \n",
       "\n",
       "   doc_sentiment_score_SUM  doc_sentiment_magnitude_MEAN  \\\n",
       "0                      1.8                           2.4   \n",
       "1                     -0.4                           0.7   \n",
       "2                      1.4                           3.7   \n",
       "3                      0.9                           0.9   \n",
       "\n",
       "   doc_sentiment_magnitude_SUM  sentence_sentiment_score_MEAN  \\\n",
       "0                         14.4                           0.30   \n",
       "1                          1.4                          -0.25   \n",
       "2                         25.9                           0.20   \n",
       "3                          0.9                           0.90   \n",
       "\n",
       "   sentence_sentiment_score_SUM  sentence_sentiment_magnitude_MEAN  \\\n",
       "0                           1.8                           0.366667   \n",
       "1                          -0.5                           0.350000   \n",
       "2                           1.4                           0.485714   \n",
       "3                           0.9                           0.900000   \n",
       "\n",
       "  sentence_sentiment_magnitude_SUM  \\\n",
       "0                              2.2   \n",
       "1                              0.7   \n",
       "2                              3.4   \n",
       "3                              0.9   \n",
       "\n",
       "                                         entity_name  \n",
       "0  Nibble cuteness clinic cats result kitty coupl...  \n",
       "1                                     apartment care  \n",
       "2  mother owner puppies roadside shops Subang Jay...  \n",
       "3        guard dog master obedience call sms details  \n",
       "\n",
       "[4 rows x 38 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features from: Description\n",
      "generating features from: entity_name\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import SparsePCA, TruncatedSVD, LatentDirichletAllocation, NMF\n",
    "\n",
    "text_columns = ['Description', 'entity_name']\n",
    "X_text= train[text_columns]\n",
    "n_components = 5\n",
    "text_features = []\n",
    "\n",
    "\n",
    "# Generate text features:\n",
    "for i in X_text.columns:\n",
    "    \n",
    "    # Initialize decomposition methods:\n",
    "    print('generating features from: {}'.format(i))\n",
    "    svd_ = TruncatedSVD(\n",
    "        n_components=n_components, random_state=1337)\n",
    "    nmf_ = NMF(\n",
    "        n_components=n_components, random_state=1337)\n",
    "    \n",
    "    tfidf_col = TfidfVectorizer().fit_transform(X_text.loc[:, i].values)\n",
    "    svd_col = svd_.fit_transform(tfidf_col)\n",
    "    svd_col = pd.DataFrame(svd_col)\n",
    "    svd_col = svd_col.add_prefix('SVD_{}_'.format(i))\n",
    "    \n",
    "    nmf_col = nmf_.fit_transform(tfidf_col)\n",
    "    nmf_col = pd.DataFrame(nmf_col)\n",
    "    nmf_col = nmf_col.add_prefix('NMF_{}_'.format(i))\n",
    "    \n",
    "    text_features.append(svd_col)\n",
    "    text_features.append(nmf_col)\n",
    "\n",
    "    \n",
    "# Combine all extracted features:\n",
    "text_features = pd.concat(text_features, axis=1)\n",
    "\n",
    "# Concatenate with main DF:\n",
    "train = pd.concat([train, text_features], axis=1)\n",
    "\n",
    "# Remove raw text columns:\n",
    "for i in X_text.columns:\n",
    "    train = train.drop(i, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14993 entries, 0 to 14992\n",
      "Data columns (total 56 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   Type                               14993 non-null  int64   \n",
      " 1   Name                               13728 non-null  object  \n",
      " 2   Age                                14993 non-null  int64   \n",
      " 3   Breed1                             14993 non-null  int64   \n",
      " 4   Breed2                             14993 non-null  int64   \n",
      " 5   Gender                             14993 non-null  int64   \n",
      " 6   Color1                             14993 non-null  int64   \n",
      " 7   Color2                             14993 non-null  int64   \n",
      " 8   Color3                             14993 non-null  int64   \n",
      " 9   MaturitySize                       14993 non-null  int64   \n",
      " 10  FurLength                          14993 non-null  int64   \n",
      " 11  Vaccinated                         14993 non-null  int64   \n",
      " 12  Dewormed                           14993 non-null  int64   \n",
      " 13  Sterilized                         14993 non-null  int64   \n",
      " 14  Health                             14993 non-null  int64   \n",
      " 15  Quantity                           14993 non-null  int64   \n",
      " 16  Fee                                14993 non-null  int64   \n",
      " 17  State                              14993 non-null  int64   \n",
      " 18  RescuerID                          14993 non-null  object  \n",
      " 19  VideoAmt                           14993 non-null  int64   \n",
      " 20  PetID                              14993 non-null  object  \n",
      " 21  PhotoAmt                           14993 non-null  float64 \n",
      " 22  AdoptionSpeed                      14993 non-null  int64   \n",
      " 23  BreedID                            14976 non-null  float64 \n",
      " 24  BreedName                          14976 non-null  object  \n",
      " 25  BreedID_SecondaryBreed             4228 non-null   float64 \n",
      " 26  BreedName_SecondaryBreed           4228 non-null   object  \n",
      " 27  Age_target                         14993 non-null  category\n",
      " 28  doc_sentiment_score_MEAN           14442 non-null  float64 \n",
      " 29  doc_sentiment_score_SUM            14442 non-null  float64 \n",
      " 30  doc_sentiment_magnitude_MEAN       14442 non-null  float64 \n",
      " 31  doc_sentiment_magnitude_SUM        14442 non-null  float64 \n",
      " 32  sentence_sentiment_score_MEAN      14442 non-null  float64 \n",
      " 33  sentence_sentiment_score_SUM       14442 non-null  float64 \n",
      " 34  sentence_sentiment_magnitude_MEAN  14442 non-null  float64 \n",
      " 35  sentence_sentiment_magnitude_SUM   14442 non-null  float64 \n",
      " 36  SVD_Description_0                  14993 non-null  float64 \n",
      " 37  SVD_Description_1                  14993 non-null  float64 \n",
      " 38  SVD_Description_2                  14993 non-null  float64 \n",
      " 39  SVD_Description_3                  14993 non-null  float64 \n",
      " 40  SVD_Description_4                  14993 non-null  float64 \n",
      " 41  NMF_Description_0                  14993 non-null  float64 \n",
      " 42  NMF_Description_1                  14993 non-null  float64 \n",
      " 43  NMF_Description_2                  14993 non-null  float64 \n",
      " 44  NMF_Description_3                  14993 non-null  float64 \n",
      " 45  NMF_Description_4                  14993 non-null  float64 \n",
      " 46  SVD_entity_name_0                  14993 non-null  float64 \n",
      " 47  SVD_entity_name_1                  14993 non-null  float64 \n",
      " 48  SVD_entity_name_2                  14993 non-null  float64 \n",
      " 49  SVD_entity_name_3                  14993 non-null  float64 \n",
      " 50  SVD_entity_name_4                  14993 non-null  float64 \n",
      " 51  NMF_entity_name_0                  14993 non-null  float64 \n",
      " 52  NMF_entity_name_1                  14993 non-null  float64 \n",
      " 53  NMF_entity_name_2                  14993 non-null  float64 \n",
      " 54  NMF_entity_name_3                  14993 non-null  float64 \n",
      " 55  NMF_entity_name_4                  14993 non-null  float64 \n",
      "dtypes: category(1), float64(31), int64(19), object(5)\n",
      "memory usage: 6.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "elimino columnas que no voy a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['PetID', 'Name', 'RescuerID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factorizo las columnas raza de mascotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['BreedName', 'BreedName_SecondaryBreed']:\n",
    "    train.loc[:, i] = pd.factorize(train.loc[:, i])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "guardo el archivo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(os.path.join(PATH_TO_SENTIMENTS_SAVE, 'train_sentimentFE_final.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
